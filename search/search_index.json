{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"loxilbdocs - Documentation about loxilb loxilb Background loxilb started as a project to ease deployments of cloud-native/kubernetes workloads for the edge. When we deploy services in public clouds like AWS/GCP, the services becomes easily accessible or exported to the outside world. The public cloud providers, usually by default, associate load-balancer instances for incoming requests to these services to ensure everything is quite smooth. However, for on-prem and edge deployments, there is no service type - external load balancer provider by default. For a long time, MetalLB from google was the only choice for the needy. But edge services are a different ball game altogether due to the fact that there are so many exotic protocols in play like GTP, SCTP, SRv6 etc and integrating everything into a seamlessly working solution has been quite difficult. loxilb dev team was approached by many people who wanted to solve this problem. As a first step to solve the problem, it became apparent that networking stack provided by Linux kernel, although very solid, really lacked the development process agility to quickly provide the permutations and combinations of protocols and the necessary encap, decap and stateful load-balancing. Our search led us to the awesome tech developed by the Linux community - eBPF. The flexibility to introduce new functionality into Kernel as a sandbox program was a complete fit to our design philosophy. Although we did consider DPDK for a while, but the fact that it needs dedicated cores/CPUs really defeats the whole purpose of making energy-efficient edge architectures. During the journey of loxilb's development, we developed many other generic networking/security/visibility features in it using eBPF which can be used for various other purposes not specific to load-balancer only. But we decided to stick our original name loxilb . loxilb team hopes the open-source community finds it helpful. loxilb Aim/Goals loxilb aims to provide the following : Service type external load-balancer for kubernetes (hence the name loxilb) L4/NAT stateful loadbalancer High-availability support K8s CCM compliance Optimized SRv6 implementation in eBPF Make GTP tunnels first class citizens of the Linux world Support for QFI and other extension headers eBPF/XDP based kernel forwarding (GPLv2 license) Complete kernel bypass with built-in advanced features like conntrack, QoS etc Highly scalable with low-latency & high througput Hybrid stack utilizing both XDP and TC-eBPF goLang based control plane components (Apache license) Seamless integration with goBGP based routing stack Easily cuztomizable to run in DPU environments goLang based easy to use APIs/Interfaces Cloud-Native Network Function (CNF) form-factor by default Documentation What is eBPF What is service type - external load-balancer Architecture in brief Code organization eBPF/XDP internals of loxilb Howto - build/run Howto - ccm plugin Howto - debug Cmd/Config guide Api guide Performance Development Roadmap Contribute FAQs Host OS requirements To install Loxilight software packages, you need the 64-bit version of one of these OS versions: * Ubuntu Focal 20.04(LTS) * Ubuntu Hirsute 21.04 * RockyOS * Enterprise Redhat (Planned) * Windows Server(Planned) Linux Kernel Requirements Linux Kernel Version >= 5.1.0 Compatible Kubernetes Versions Kubernetes 1.19 Kubernetes 1.20 Kubernetes 1.21 Kubernetes 1.22","title":"Home"},{"location":"#loxilbdocs-documentation-about-loxilb","text":"","title":"loxilbdocs - Documentation about loxilb"},{"location":"#loxilb-background","text":"loxilb started as a project to ease deployments of cloud-native/kubernetes workloads for the edge. When we deploy services in public clouds like AWS/GCP, the services becomes easily accessible or exported to the outside world. The public cloud providers, usually by default, associate load-balancer instances for incoming requests to these services to ensure everything is quite smooth. However, for on-prem and edge deployments, there is no service type - external load balancer provider by default. For a long time, MetalLB from google was the only choice for the needy. But edge services are a different ball game altogether due to the fact that there are so many exotic protocols in play like GTP, SCTP, SRv6 etc and integrating everything into a seamlessly working solution has been quite difficult. loxilb dev team was approached by many people who wanted to solve this problem. As a first step to solve the problem, it became apparent that networking stack provided by Linux kernel, although very solid, really lacked the development process agility to quickly provide the permutations and combinations of protocols and the necessary encap, decap and stateful load-balancing. Our search led us to the awesome tech developed by the Linux community - eBPF. The flexibility to introduce new functionality into Kernel as a sandbox program was a complete fit to our design philosophy. Although we did consider DPDK for a while, but the fact that it needs dedicated cores/CPUs really defeats the whole purpose of making energy-efficient edge architectures. During the journey of loxilb's development, we developed many other generic networking/security/visibility features in it using eBPF which can be used for various other purposes not specific to load-balancer only. But we decided to stick our original name loxilb . loxilb team hopes the open-source community finds it helpful.","title":"loxilb Background"},{"location":"#loxilb-aimgoals","text":"loxilb aims to provide the following : Service type external load-balancer for kubernetes (hence the name loxilb) L4/NAT stateful loadbalancer High-availability support K8s CCM compliance Optimized SRv6 implementation in eBPF Make GTP tunnels first class citizens of the Linux world Support for QFI and other extension headers eBPF/XDP based kernel forwarding (GPLv2 license) Complete kernel bypass with built-in advanced features like conntrack, QoS etc Highly scalable with low-latency & high througput Hybrid stack utilizing both XDP and TC-eBPF goLang based control plane components (Apache license) Seamless integration with goBGP based routing stack Easily cuztomizable to run in DPU environments goLang based easy to use APIs/Interfaces Cloud-Native Network Function (CNF) form-factor by default","title":"loxilb Aim/Goals"},{"location":"#documentation","text":"What is eBPF What is service type - external load-balancer Architecture in brief Code organization eBPF/XDP internals of loxilb Howto - build/run Howto - ccm plugin Howto - debug Cmd/Config guide Api guide Performance Development Roadmap Contribute FAQs","title":"Documentation"},{"location":"#host-os-requirements","text":"To install Loxilight software packages, you need the 64-bit version of one of these OS versions: * Ubuntu Focal 20.04(LTS) * Ubuntu Hirsute 21.04 * RockyOS * Enterprise Redhat (Planned) * Windows Server(Planned)","title":"Host OS requirements"},{"location":"#linux-kernel-requirements","text":"Linux Kernel Version >= 5.1.0","title":"Linux Kernel Requirements"},{"location":"#compatible-kubernetes-versions","text":"Kubernetes 1.19 Kubernetes 1.20 Kubernetes 1.21 Kubernetes 1.22","title":"Compatible Kubernetes Versions"},{"location":"api/","text":"API server Generic library for building a LoxiLB API server. Usage \ud604\uc7ac API \uc11c\ubc84\ub294 HTTP, HTTPS\ubaa8\ub450 \uc9c0\uc6d0\ud558\uba70, Loxilb \uc2e4\ud589\uc2dc -a \ud639\uc740 --api \uc635\uc158\uc744 \ucd94\uac00\ud574\uc11c \uc2e4\ud589\uc774 \uac00\ub2a5\ud558\ub2e4. API\uc5d0 \uc0ac\uc6a9\ub418\ub294 \uc635\uc158\uc740 \ub2e4\uc74c\uacfc \uac19\ub2e4. \ubcf4\uc548\uc744 \uc704\ud574 HTTPS \uc635\uc158 --tls-key, --tls-certificate\ub97c \ubaa8\ub450 \uc8fc\uc5b4\uc57c\ub9cc \uc2e4\ud589\uc774 \uac00\ub2a5\ud558\ub2e4. Currently, the API server supports both HTTP and HTTPS, and can be run by adding -a or --api options when running Loxilb. The options used in the API are as follows. For security purposes, HTTPS options --tls-key, --tls-certificate must be given to run. --host= the IP to listen on (default: localhost) [$HOST] --port= the port to listen on for insecure connections, defaults to a random value [$PORT] --tls-host= the IP to listen on for tls, when not specified it's the same as --host [$TLS_HOST] --tls-port= the port to listen on for secure connections, defaults to a random value [$TLS_PORT] --tls-certificate= the certificate to use for secure connections [$TLS_CERTIFICATE] --tls-key= the private key to use for secure connections [$TLS_PRIVATE_KEY] \uc2e4\uc81c \uc0ac\uc6a9\ud558\ub294 \uc608\uc2dc\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4. Examples of practical use are as follows. ./loxilb --tls-key=api/certification/server.key --tls-certificate=api/certification/server.crt --host=0.0.0.0 --port=8081 --tls-port=8091 -a API list \ud604\uc7ac API\ub294 Load balancer \uc5d0 \ub300\ud55c Create, Delete, Read API\uac00 \uc788\ub2e4. Currently, the API has Create, Delete, and Read APIs for Load balancer. Method URL Role GET /netlox/v1/config/loadbalancer/all Get the load balancer information POST /netlox/v1/config/loadbalancer Add the load balancer information to LoxiLB DELETE /netlox/v1/config/loadbalancer/externalipaddress/{IPaddress}/port/{#Port}/protocol/{protocol} Delete the load balacer infomation from LoxiLB \ub354 \uc790\uc138\ud55c \uc815\ubcf4( Param, Body \ub4f1)\uc740 Swagger\ubb38\uc11c\ub97c \ucc38\uc870\ud55c\ub2e4. See Swagger documentation for more information (Param, Body, etc.).","title":"Api guide"},{"location":"api/#api-server","text":"Generic library for building a LoxiLB API server.","title":"API server"},{"location":"api/#usage","text":"\ud604\uc7ac API \uc11c\ubc84\ub294 HTTP, HTTPS\ubaa8\ub450 \uc9c0\uc6d0\ud558\uba70, Loxilb \uc2e4\ud589\uc2dc -a \ud639\uc740 --api \uc635\uc158\uc744 \ucd94\uac00\ud574\uc11c \uc2e4\ud589\uc774 \uac00\ub2a5\ud558\ub2e4. API\uc5d0 \uc0ac\uc6a9\ub418\ub294 \uc635\uc158\uc740 \ub2e4\uc74c\uacfc \uac19\ub2e4. \ubcf4\uc548\uc744 \uc704\ud574 HTTPS \uc635\uc158 --tls-key, --tls-certificate\ub97c \ubaa8\ub450 \uc8fc\uc5b4\uc57c\ub9cc \uc2e4\ud589\uc774 \uac00\ub2a5\ud558\ub2e4. Currently, the API server supports both HTTP and HTTPS, and can be run by adding -a or --api options when running Loxilb. The options used in the API are as follows. For security purposes, HTTPS options --tls-key, --tls-certificate must be given to run. --host= the IP to listen on (default: localhost) [$HOST] --port= the port to listen on for insecure connections, defaults to a random value [$PORT] --tls-host= the IP to listen on for tls, when not specified it's the same as --host [$TLS_HOST] --tls-port= the port to listen on for secure connections, defaults to a random value [$TLS_PORT] --tls-certificate= the certificate to use for secure connections [$TLS_CERTIFICATE] --tls-key= the private key to use for secure connections [$TLS_PRIVATE_KEY] \uc2e4\uc81c \uc0ac\uc6a9\ud558\ub294 \uc608\uc2dc\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4. Examples of practical use are as follows. ./loxilb --tls-key=api/certification/server.key --tls-certificate=api/certification/server.crt --host=0.0.0.0 --port=8081 --tls-port=8091 -a","title":"Usage"},{"location":"api/#api-list","text":"\ud604\uc7ac API\ub294 Load balancer \uc5d0 \ub300\ud55c Create, Delete, Read API\uac00 \uc788\ub2e4. Currently, the API has Create, Delete, and Read APIs for Load balancer. Method URL Role GET /netlox/v1/config/loadbalancer/all Get the load balancer information POST /netlox/v1/config/loadbalancer Add the load balancer information to LoxiLB DELETE /netlox/v1/config/loadbalancer/externalipaddress/{IPaddress}/port/{#Port}/protocol/{protocol} Delete the load balacer infomation from LoxiLB \ub354 \uc790\uc138\ud55c \uc815\ubcf4( Param, Body \ub4f1)\uc740 Swagger\ubb38\uc11c\ub97c \ucc38\uc870\ud55c\ub2e4. See Swagger documentation for more information (Param, Body, etc.).","title":"API list"},{"location":"arch/","text":"loxilb architecture and modules loxilb consists of the following modules : - loxilb CCM plugin \\ It fully implements K8s CCM load-balancer interface and talks to goLang based loxilb process using Restful APIs. Although loxilb CCM is logically shown as part of loxilb cluster nodes, it will usually run in one of the worker/master nodes of the K8s cluster. loxicmd \\ loxicmd is command line tool to configure and dump loxilb information which is based on same foundation as the wildly popular kubectl tools loxilb \\ loxilb is a modern goLang based framework (process) which mantains information coming in from various sources e.g apiserver and populates the eBPF maps used by the loxilb eBPF kernel. It is also responsible for loading eBPF programs to the interfaces.It also acts as a client to goBGP to exchange routes based on information from loxilb CCM. Last but not the least, it will be finally responsible for maintaining HA state sync with its remote peers. Almost all serious lb implementations need to be deployed as a HA cluster. loxilb eBPF kernel \\ eBPF kernel module implements the data-plane of loxilb which provides complete kernel bypass. It is a fully self contained and feature-rich stack able to process packets from rx to tx without invoking linux native kernel networking. goBGP \\ Although goBGP is a separate project, loxilb has adopted and integrated with goBGP as its routing stack of choice. We also hope to develop features for this awesome project in the future. DashBoards \\ Grafana based dashboards to provide highly dynamic insight into loxilb state. The following is a typical loxilb deployment topology (Currently HA implementation is in development) :","title":"Architecture in brief"},{"location":"arch/#loxilb-architecture-and-modules","text":"loxilb consists of the following modules : - loxilb CCM plugin \\ It fully implements K8s CCM load-balancer interface and talks to goLang based loxilb process using Restful APIs. Although loxilb CCM is logically shown as part of loxilb cluster nodes, it will usually run in one of the worker/master nodes of the K8s cluster. loxicmd \\ loxicmd is command line tool to configure and dump loxilb information which is based on same foundation as the wildly popular kubectl tools loxilb \\ loxilb is a modern goLang based framework (process) which mantains information coming in from various sources e.g apiserver and populates the eBPF maps used by the loxilb eBPF kernel. It is also responsible for loading eBPF programs to the interfaces.It also acts as a client to goBGP to exchange routes based on information from loxilb CCM. Last but not the least, it will be finally responsible for maintaining HA state sync with its remote peers. Almost all serious lb implementations need to be deployed as a HA cluster. loxilb eBPF kernel \\ eBPF kernel module implements the data-plane of loxilb which provides complete kernel bypass. It is a fully self contained and feature-rich stack able to process packets from rx to tx without invoking linux native kernel networking. goBGP \\ Although goBGP is a separate project, loxilb has adopted and integrated with goBGP as its routing stack of choice. We also hope to develop features for this awesome project in the future. DashBoards \\ Grafana based dashboards to provide highly dynamic insight into loxilb state. The following is a typical loxilb deployment topology (Currently HA implementation is in development) :","title":"loxilb architecture and modules"},{"location":"cmd/","text":"What is loxicmd loxicmd is command tools for loxilb. loxicmd provide the following : Add/Delete/Get about the service type external load-balancer Get Port(interface) dump Get Connection track information loxicmd aim to provide all of the configuation for the loxilb. How to build Install package dependencies go get . Make loxicmd make How to run Run loxicmd with getting lb information ./loxicmd get lb Run loxicmd with getting lb information in the different API server(ex. 192.168.18.10) and ports(ex. 8099). ./loxicmd get lb -s 192.168.18.10 -p 8099 Run loxicmd with getting lb information as json output format ./loxicmd get lb -o json Run loxicmd with adding lb information ./loxicmd create lb 1.1.1.1 --tcp=1828:1920 --endpoints=2.2.3.4:18 Run loxicmd with deleting lb information ./loxicmd delete lb 1.1.1.1 --tcp=1828:1920 Run loxicmd with getting connection track information ./loxicmd get conntrack Run loxicmd with getting port dumps ./loxicmd get port More information use help option! ./loxicmd help","title":"Cmd/Config guid"},{"location":"cmd/#what-is-loxicmd","text":"loxicmd is command tools for loxilb. loxicmd provide the following : Add/Delete/Get about the service type external load-balancer Get Port(interface) dump Get Connection track information loxicmd aim to provide all of the configuation for the loxilb.","title":"What is loxicmd"},{"location":"cmd/#how-to-build","text":"Install package dependencies go get . Make loxicmd make","title":"How to build"},{"location":"cmd/#how-to-run","text":"Run loxicmd with getting lb information ./loxicmd get lb Run loxicmd with getting lb information in the different API server(ex. 192.168.18.10) and ports(ex. 8099). ./loxicmd get lb -s 192.168.18.10 -p 8099 Run loxicmd with getting lb information as json output format ./loxicmd get lb -o json Run loxicmd with adding lb information ./loxicmd create lb 1.1.1.1 --tcp=1828:1920 --endpoints=2.2.3.4:18 Run loxicmd with deleting lb information ./loxicmd delete lb 1.1.1.1 --tcp=1828:1920 Run loxicmd with getting connection track information ./loxicmd get conntrack Run loxicmd with getting port dumps ./loxicmd get port More information use help option! ./loxicmd help","title":"How to run"},{"location":"code/","text":"loxilb is organized as below: \u251c\u2500\u2500 api \u2502 \u251c\u2500\u2500 certification \u2502 \u251c\u2500\u2500 cmd \u2502 \u2502 \u251c\u2500\u2500 loxilb-rest-api-server \u2502 \u251c\u2500\u2500 models \u2502 \u251c\u2500\u2500 restapi \u2502 \u251c\u2500\u2500 handler \u2502 \u251c\u2500\u2500 operations \u251c\u2500\u2500 common \u251c\u2500\u2500 ebpf \u2502 \u251c\u2500\u2500 common \u2502 \u251c\u2500\u2500 headers \u2502 \u2502 \u251c\u2500\u2500 linux \u2502 \u251c\u2500\u2500 kernel \u2502 \u251c\u2500\u2500 libbpf \u2502 \u2502 \u251c\u2500\u2500 include \u2502 \u2502 \u2502 \u251c\u2500\u2500 asm \u2502 \u2502 \u2502 \u251c\u2500\u2500 linux \u2502 \u2502 \u2502 \u251c\u2500\u2500 uapi \u2502 \u2502 \u2502 \u251c\u2500\u2500 linux \u2502 \u2502 \u251c\u2500\u2500 scripts \u2502 \u2502 \u251c\u2500\u2500 src \u2502 \u2502 \u2502 \u251c\u2500\u2500 build \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 usr \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 include \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 bpf \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 lib64 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 pkgconfig \u2502 \u2502 \u2502 \u251c\u2500\u2500 sharedobjs \u2502 \u2502 \u2502 \u251c\u2500\u2500 staticobjs \u2502 \u2502 \u251c\u2500\u2500 travis-ci \u2502 \u2502 \u251c\u2500\u2500 managers \u2502 \u2502 \u251c\u2500\u2500 vmtest \u2502 \u2502 \u251c\u2500\u2500 configs \u2502 \u2502 \u251c\u2500\u2500 blacklist \u2502 \u2502 \u251c\u2500\u2500 whitelist \u2502 \u251c\u2500\u2500 utils \u251c\u2500\u2500 loxilib \u251c\u2500\u2500 loxinet \u251c\u2500\u2500 loxinlp \u251c\u2500\u2500 options api This directory contains source code to host api server to handle CCM configuration requests. common Common api to configure which are exposed by loxinet are defined in this directory. loxinet This module implements the glue layer or the middle layer between eBPF datapath module and api modules. It defines functions for configuring networking and load balancing rules in the eBPF datapath. ebpf This directory contains source code for loxilb eBPF datapath. loxilib This directory contains common libraries for logging, statistics and other utilities. loxinlp This directory implements the package for reading and writing the network information through linux's netlink interface. options This directory contains files for managing the command line options.","title":"Code organization"},{"location":"code/#loxilb-is-organized-as-below","text":"\u251c\u2500\u2500 api \u2502 \u251c\u2500\u2500 certification \u2502 \u251c\u2500\u2500 cmd \u2502 \u2502 \u251c\u2500\u2500 loxilb-rest-api-server \u2502 \u251c\u2500\u2500 models \u2502 \u251c\u2500\u2500 restapi \u2502 \u251c\u2500\u2500 handler \u2502 \u251c\u2500\u2500 operations \u251c\u2500\u2500 common \u251c\u2500\u2500 ebpf \u2502 \u251c\u2500\u2500 common \u2502 \u251c\u2500\u2500 headers \u2502 \u2502 \u251c\u2500\u2500 linux \u2502 \u251c\u2500\u2500 kernel \u2502 \u251c\u2500\u2500 libbpf \u2502 \u2502 \u251c\u2500\u2500 include \u2502 \u2502 \u2502 \u251c\u2500\u2500 asm \u2502 \u2502 \u2502 \u251c\u2500\u2500 linux \u2502 \u2502 \u2502 \u251c\u2500\u2500 uapi \u2502 \u2502 \u2502 \u251c\u2500\u2500 linux \u2502 \u2502 \u251c\u2500\u2500 scripts \u2502 \u2502 \u251c\u2500\u2500 src \u2502 \u2502 \u2502 \u251c\u2500\u2500 build \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 usr \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 include \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 bpf \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 lib64 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 pkgconfig \u2502 \u2502 \u2502 \u251c\u2500\u2500 sharedobjs \u2502 \u2502 \u2502 \u251c\u2500\u2500 staticobjs \u2502 \u2502 \u251c\u2500\u2500 travis-ci \u2502 \u2502 \u251c\u2500\u2500 managers \u2502 \u2502 \u251c\u2500\u2500 vmtest \u2502 \u2502 \u251c\u2500\u2500 configs \u2502 \u2502 \u251c\u2500\u2500 blacklist \u2502 \u2502 \u251c\u2500\u2500 whitelist \u2502 \u251c\u2500\u2500 utils \u251c\u2500\u2500 loxilib \u251c\u2500\u2500 loxinet \u251c\u2500\u2500 loxinlp \u251c\u2500\u2500 options","title":"loxilb is organized as below:"},{"location":"code/#api","text":"This directory contains source code to host api server to handle CCM configuration requests.","title":"api"},{"location":"code/#common","text":"Common api to configure which are exposed by loxinet are defined in this directory.","title":"common"},{"location":"code/#loxinet","text":"This module implements the glue layer or the middle layer between eBPF datapath module and api modules. It defines functions for configuring networking and load balancing rules in the eBPF datapath.","title":"loxinet"},{"location":"code/#ebpf","text":"This directory contains source code for loxilb eBPF datapath.","title":"ebpf"},{"location":"code/#loxilib","text":"This directory contains common libraries for logging, statistics and other utilities.","title":"loxilib"},{"location":"code/#loxinlp","text":"This directory implements the package for reading and writing the network information through linux's netlink interface.","title":"loxinlp"},{"location":"code/#options","text":"This directory contains files for managing the command line options.","title":"options"},{"location":"debugging/","text":"loxilb - How to debug Check loxilb logs loxilb logs its various important events and logs in the file /var/log/loxilb.log. Users can check it by using tail -f or any other command of choice. root@752531364e2c:/# tail -f /var/log/loxilb.log DBG: 2022/07/10 12:49:27 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:49:37 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:49:47 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:49:57 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:07 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:17 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:27 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:37 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:47 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:57 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 Check loxicmd to debug loxilb's internal state ## Spawn a bash shell of loxilb docker docker exec -it loxilb bash root@752531364e2c:/# loxicmd get lb | EXTERNALIP | PORT | PROTOCOL | SELECT | # OF ENDPOINTS | |------------|------|----------|--------|----------------| | 10.10.10.1 | 2020 | tcp | 0 | 3 | root@752531364e2c:/# loxicmd get lb -o wide | EXTERNALIP | PORT | PROTOCOL | SELECT | ENDPOINTIP | TARGETPORT | WEIGHT | |------------|------|----------|--------|---------------|------------|--------| | 10.10.10.1 | 2020 | tcp | 0 | 31.31.31.1 | 5001 | 1 | | | | | | 32.32.32.1 | 5001 | 2 | | | | | | 100.100.100.1 | 5001 | 2 | root@0c4f9175c983:/# loxicmd get conntrack | DESTINATIONIP | SOURCEIP | DESTINATIONPORT | SOURCEPORT | PROTOCOL | STATE | ACT | |---------------|------------|-----------------|------------|----------|-------------|-----| | 127.0.0.1 | 127.0.0.1 | 11111 | 47180 | tcp | closed-wait | | | 127.0.0.1 | 127.0.0.1 | 11111 | 47182 | tcp | est | | | 32.32.32.1 | 31.31.31.1 | 35068 | 35068 | icmp | bidir | | root@65ad9b2f1b7f:/# loxicmd get port | INDEX | PORTNAME | MAC | LINK/STATE | L3INFO | L2INFO | |-------|----------|-------------------|-------------|---------------|---------------| | 1 | lo | 00:00:00:00:00:00 | true/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3801 | | | | | | IPv6 : [] | | | 2 | vlan3801 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3801 | | | | | | IPv6 : [] | | | 3 | llb0 | 42:6e:9b:7f:ff:36 | true/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3803 | | | | | | IPv6 : [] | | | 4 | vlan3803 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3803 | | | | | | IPv6 : [] | | | 5 | eth0 | 02:42:ac:1e:01:c1 | true/true | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3805 | | | | | | IPv6 : [] | | | 6 | vlan3805 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3805 | | | | | | IPv6 : [] | | | 7 | enp1 | fe:84:23:ac:41:31 | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3807 | | | | | | IPv6 : [] | | | 8 | vlan3807 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3807 | | | | | | IPv6 : [] | | | 9 | enp2 | d6:3c:7f:9e:58:5c | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3809 | | | | | | IPv6 : [] | | | 10 | vlan3809 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3809 | | | | | | IPv6 : [] | | | 11 | enp2v15 | 8a:9e:99:aa:f9:c3 | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3811 | | | | | | IPv6 : [] | | | 12 | vlan3811 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3811 | | | | | | IPv6 : [] | | | 13 | enp3 | f2:c7:4b:ac:fd:3e | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3813 | | | | | | IPv6 : [] | | | 14 | vlan3813 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3813 | | | | | | IPv6 : [] | | | 15 | enp4 | 12:d2:c3:79:f3:6a | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3815 | | | | | | IPv6 : [] | | | 16 | vlan3815 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3815 | | | | | | IPv6 : [] | | | 17 | vlan100 | 56:2e:76:b2:71:48 | false/false | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 100 | | | | | | IPv6 : [] | | Debug loxilb kernel and eBPF components loxilb uses various eBPF maps as part of its DP implementation. These maps are pinned to OS filesystem and can be further used with bpftool to debug. root@0c4f9175c983:/# ls -lart /opt/loxilb/dp/bpf/ total 0 -rw------- 1 root root 0 Jul 10 11:32 xfis -rw------- 1 root root 0 Jul 10 11:32 xfck -rw------- 1 root root 0 Jul 10 11:32 xctk -rw------- 1 root root 0 Jul 10 11:32 tx_intf_stats_map -rw------- 1 root root 0 Jul 10 11:32 tx_intf_map -rw------- 1 root root 0 Jul 10 11:32 tx_bd_stats_map -rw------- 1 root root 0 Jul 10 11:32 tmac_stats_map -rw------- 1 root root 0 Jul 10 11:32 tmac_map -rw------- 1 root root 0 Jul 10 11:32 smac_map -rw------- 1 root root 0 Jul 10 11:32 sess_v4_stats_map -rw------- 1 root root 0 Jul 10 11:32 sess_v4_map -rw------- 1 root root 0 Jul 10 11:32 rt_v6_stats_map -rw------- 1 root root 0 Jul 10 11:32 rt_v4_stats_map -rw------- 1 root root 0 Jul 10 11:32 rt_v4_map -rw------- 1 root root 0 Jul 10 11:32 polx_map -rw------- 1 root root 0 Jul 10 11:32 pkts -rw------- 1 root root 0 Jul 10 11:32 pkt_ring -rw------- 1 root root 0 Jul 10 11:32 pgm_tbl -rw------- 1 root root 0 Jul 10 11:32 nat_v4_map -rw------- 1 root root 0 Jul 10 11:32 mirr_map -rw------- 1 root root 0 Jul 10 11:32 intf_stats_map -rw------- 1 root root 0 Jul 10 11:32 intf_map -rw------- 1 root root 0 Jul 10 11:32 fcas -rw------- 1 root root 0 Jul 10 11:32 fc_v4_stats_map -rw------- 1 root root 0 Jul 10 11:32 fc_v4_map -rw------- 1 root root 0 Jul 10 11:32 dmac_map -rw------- 1 root root 0 Jul 10 11:32 ct_v4_map -rw------- 1 root root 0 Jul 10 11:32 bd_stats_map -rw------- 1 root root 0 Jul 10 11:32 acl_v6_stats_map -rw------- 1 root root 0 Jul 10 11:32 acl_v4_stats_map -rw------- 1 root root 0 Jul 10 11:32 acl_v4_map drwxrwxrwt 3 root root 0 Jul 10 11:32 .. lrwxrwxrwx 1 root root 0 Jul 10 11:32 xdp -> /opt/loxilb/dp/bpf//tc/ drwx------ 3 root root 0 Jul 10 11:32 tc lrwxrwxrwx 1 root root 0 Jul 10 11:32 ip -> /opt/loxilb/dp/bpf//tc/ root@752531364e2c:/# bpftool map dump pinned /opt/loxilb/dp/bpf/intf_map [{ \"key\": { \"ifindex\": 2, \"ing_vid\": 0, \"pad\": 0 }, \"value\": { \"ca\": { \"act_type\": 11, \"ftrap\": 0, \"oif\": 0, \"cidx\": 0 }, \"\": { \"set_ifi\": { \"xdp_ifidx\": 1, \"zone\": 0, \"bd\": 3801, \"mirr\": 0, \"polid\": 0, \"r\": [0,0,0,0,0,0 ] } } } },{ \"key\": { \"ifindex\": 3, \"ing_vid\": 0, \"pad\": 0 }, \"value\": { \"ca\": { \"act_type\": 11, \"ftrap\": 0, \"oif\": 0, \"cidx\": 0 }, \"\": { \"set_ifi\": { \"xdp_ifidx\": 3, \"zone\": 0, \"bd\": 3803, \"mirr\": 0, \"polid\": 0, \"r\": [0,0,0,0,0,0 ] } } } } ] root@752531364e2c:/# bpftool map dump pinned /opt/loxilb/dp/bpf/nat_v4_map [{ \"key\": { \"daddr\": 17435146, \"dport\": 58375, \"zone\": 0, \"l4proto\": 6 }, \"value\": { \"ca\": { \"act_type\": 5, \"ftrap\": 0, \"oif\": 0, \"cidx\": 1 }, \"lock\": { \"val\": 0 }, \"nxfrm\": 3, \"sel_hint\": 0, \"sel_type\": 0, \"nxfrms\": [{ \"nat_flags\": 0, \"inactive\": 0, \"wprio\": 1, \"res\": 0, \"nat_xport\": 35091, \"nat_xip\": 18816799 },{ \"nat_flags\": 0, \"inactive\": 0, \"wprio\": 2, \"res\": 0, \"nat_xport\": 35091, \"nat_xip\": 18882592 },{ \"nat_flags\": 0, \"inactive\": 0, \"wprio\": 2, \"res\": 0, \"nat_xport\": 35091, \"nat_xip\": 23356516 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 } ] } } ] Check eBPF kernel debug logs Last but not the least, linux kernel outputs generic eBPF debug logs to /sys/kernel/debug/tracing/trace_pipe. Although loxilb eBPF modules do not emit logs in normal mode of operation, logs can be enabled after a recompilation. root@752531364e2c:/# cat /sys/kernel/debug/tracing/trace_pipe loxicmd-30524 [001] d.s1 27870.170790: bpf_trace_printk: out-dir loxicmd-30524 [001] d.s1 27870.170791: bpf_trace_printk: smr 4 loxicmd-30529 [000] d.s1 27871.617467: bpf_trace_printk: [CTRK] start loxicmd-30529 [000] d.s1 27871.617484: bpf_trace_printk: new-ct4 loxicmd-30529 [000] d.s1 27871.617486: bpf_trace_printk: in-dir loxicmd-30529 [000] d.s1 27871.617488: bpf_trace_printk: smr 0 loxicmd-30529 [000] d.s1 27871.617503: bpf_trace_printk: [CTRK] start loxicmd-30529 [000] d.s1 27871.617503: bpf_trace_printk: out-dir loxicmd-30529 [000] d.s1 27871.617504: bpf_trace_printk: smr 4 sshd-30790 [000] d.s1 27970.031847: bpf_trace_printk: [CTRK] start sshd-30790 [000] d.s1 27970.031866: bpf_trace_printk: new-ct4 sshd-30790 [000] d.s1 27970.031868: bpf_trace_printk: in-dir sshd-30790 [000] d.s1 27970.031870: bpf_trace_printk: smr 0 sshd-30790 [000] d.s1 27970.031887: bpf_trace_printk: [CTRK] start sshd-30790 [000] d.s1 27970.031887: bpf_trace_printk: out-dir sshd-30790 [000] d.s1 27970.031888: bpf_trace_printk: smr 0 sshd-30790 [000] d.s1 27970.031900: bpf_trace_printk: [CTRK] start","title":"How to debug"},{"location":"debugging/#loxilb-how-to-debug","text":"Check loxilb logs loxilb logs its various important events and logs in the file /var/log/loxilb.log. Users can check it by using tail -f or any other command of choice. root@752531364e2c:/# tail -f /var/log/loxilb.log DBG: 2022/07/10 12:49:27 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:49:37 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:49:47 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:49:57 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:07 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:17 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:27 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:37 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:47 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 DBG: 2022/07/10 12:50:57 1:dst-10.10.10.1/32,proto-6,dport-2020,,do-dnat:eip-31.31.31.1,ep-5001,w-1,alive|eip-32.32.32.1,ep-5001,w-2,alive|eip-100.100.100.1,ep-5001,w-2,alive| pc 0 bc 0 Check loxicmd to debug loxilb's internal state ## Spawn a bash shell of loxilb docker docker exec -it loxilb bash root@752531364e2c:/# loxicmd get lb | EXTERNALIP | PORT | PROTOCOL | SELECT | # OF ENDPOINTS | |------------|------|----------|--------|----------------| | 10.10.10.1 | 2020 | tcp | 0 | 3 | root@752531364e2c:/# loxicmd get lb -o wide | EXTERNALIP | PORT | PROTOCOL | SELECT | ENDPOINTIP | TARGETPORT | WEIGHT | |------------|------|----------|--------|---------------|------------|--------| | 10.10.10.1 | 2020 | tcp | 0 | 31.31.31.1 | 5001 | 1 | | | | | | 32.32.32.1 | 5001 | 2 | | | | | | 100.100.100.1 | 5001 | 2 | root@0c4f9175c983:/# loxicmd get conntrack | DESTINATIONIP | SOURCEIP | DESTINATIONPORT | SOURCEPORT | PROTOCOL | STATE | ACT | |---------------|------------|-----------------|------------|----------|-------------|-----| | 127.0.0.1 | 127.0.0.1 | 11111 | 47180 | tcp | closed-wait | | | 127.0.0.1 | 127.0.0.1 | 11111 | 47182 | tcp | est | | | 32.32.32.1 | 31.31.31.1 | 35068 | 35068 | icmp | bidir | | root@65ad9b2f1b7f:/# loxicmd get port | INDEX | PORTNAME | MAC | LINK/STATE | L3INFO | L2INFO | |-------|----------|-------------------|-------------|---------------|---------------| | 1 | lo | 00:00:00:00:00:00 | true/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3801 | | | | | | IPv6 : [] | | | 2 | vlan3801 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3801 | | | | | | IPv6 : [] | | | 3 | llb0 | 42:6e:9b:7f:ff:36 | true/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3803 | | | | | | IPv6 : [] | | | 4 | vlan3803 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3803 | | | | | | IPv6 : [] | | | 5 | eth0 | 02:42:ac:1e:01:c1 | true/true | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3805 | | | | | | IPv6 : [] | | | 6 | vlan3805 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3805 | | | | | | IPv6 : [] | | | 7 | enp1 | fe:84:23:ac:41:31 | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3807 | | | | | | IPv6 : [] | | | 8 | vlan3807 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3807 | | | | | | IPv6 : [] | | | 9 | enp2 | d6:3c:7f:9e:58:5c | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3809 | | | | | | IPv6 : [] | | | 10 | vlan3809 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3809 | | | | | | IPv6 : [] | | | 11 | enp2v15 | 8a:9e:99:aa:f9:c3 | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3811 | | | | | | IPv6 : [] | | | 12 | vlan3811 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3811 | | | | | | IPv6 : [] | | | 13 | enp3 | f2:c7:4b:ac:fd:3e | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3813 | | | | | | IPv6 : [] | | | 14 | vlan3813 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3813 | | | | | | IPv6 : [] | | | 15 | enp4 | 12:d2:c3:79:f3:6a | false/false | Routed: false | IsPVID: true | | | | | | IPv4 : [] | VID : 3815 | | | | | | IPv6 : [] | | | 16 | vlan3815 | aa:bb:cc:dd:ee:ff | true/true | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 3815 | | | | | | IPv6 : [] | | | 17 | vlan100 | 56:2e:76:b2:71:48 | false/false | Routed: false | IsPVID: false | | | | | | IPv4 : [] | VID : 100 | | | | | | IPv6 : [] | | Debug loxilb kernel and eBPF components loxilb uses various eBPF maps as part of its DP implementation. These maps are pinned to OS filesystem and can be further used with bpftool to debug. root@0c4f9175c983:/# ls -lart /opt/loxilb/dp/bpf/ total 0 -rw------- 1 root root 0 Jul 10 11:32 xfis -rw------- 1 root root 0 Jul 10 11:32 xfck -rw------- 1 root root 0 Jul 10 11:32 xctk -rw------- 1 root root 0 Jul 10 11:32 tx_intf_stats_map -rw------- 1 root root 0 Jul 10 11:32 tx_intf_map -rw------- 1 root root 0 Jul 10 11:32 tx_bd_stats_map -rw------- 1 root root 0 Jul 10 11:32 tmac_stats_map -rw------- 1 root root 0 Jul 10 11:32 tmac_map -rw------- 1 root root 0 Jul 10 11:32 smac_map -rw------- 1 root root 0 Jul 10 11:32 sess_v4_stats_map -rw------- 1 root root 0 Jul 10 11:32 sess_v4_map -rw------- 1 root root 0 Jul 10 11:32 rt_v6_stats_map -rw------- 1 root root 0 Jul 10 11:32 rt_v4_stats_map -rw------- 1 root root 0 Jul 10 11:32 rt_v4_map -rw------- 1 root root 0 Jul 10 11:32 polx_map -rw------- 1 root root 0 Jul 10 11:32 pkts -rw------- 1 root root 0 Jul 10 11:32 pkt_ring -rw------- 1 root root 0 Jul 10 11:32 pgm_tbl -rw------- 1 root root 0 Jul 10 11:32 nat_v4_map -rw------- 1 root root 0 Jul 10 11:32 mirr_map -rw------- 1 root root 0 Jul 10 11:32 intf_stats_map -rw------- 1 root root 0 Jul 10 11:32 intf_map -rw------- 1 root root 0 Jul 10 11:32 fcas -rw------- 1 root root 0 Jul 10 11:32 fc_v4_stats_map -rw------- 1 root root 0 Jul 10 11:32 fc_v4_map -rw------- 1 root root 0 Jul 10 11:32 dmac_map -rw------- 1 root root 0 Jul 10 11:32 ct_v4_map -rw------- 1 root root 0 Jul 10 11:32 bd_stats_map -rw------- 1 root root 0 Jul 10 11:32 acl_v6_stats_map -rw------- 1 root root 0 Jul 10 11:32 acl_v4_stats_map -rw------- 1 root root 0 Jul 10 11:32 acl_v4_map drwxrwxrwt 3 root root 0 Jul 10 11:32 .. lrwxrwxrwx 1 root root 0 Jul 10 11:32 xdp -> /opt/loxilb/dp/bpf//tc/ drwx------ 3 root root 0 Jul 10 11:32 tc lrwxrwxrwx 1 root root 0 Jul 10 11:32 ip -> /opt/loxilb/dp/bpf//tc/ root@752531364e2c:/# bpftool map dump pinned /opt/loxilb/dp/bpf/intf_map [{ \"key\": { \"ifindex\": 2, \"ing_vid\": 0, \"pad\": 0 }, \"value\": { \"ca\": { \"act_type\": 11, \"ftrap\": 0, \"oif\": 0, \"cidx\": 0 }, \"\": { \"set_ifi\": { \"xdp_ifidx\": 1, \"zone\": 0, \"bd\": 3801, \"mirr\": 0, \"polid\": 0, \"r\": [0,0,0,0,0,0 ] } } } },{ \"key\": { \"ifindex\": 3, \"ing_vid\": 0, \"pad\": 0 }, \"value\": { \"ca\": { \"act_type\": 11, \"ftrap\": 0, \"oif\": 0, \"cidx\": 0 }, \"\": { \"set_ifi\": { \"xdp_ifidx\": 3, \"zone\": 0, \"bd\": 3803, \"mirr\": 0, \"polid\": 0, \"r\": [0,0,0,0,0,0 ] } } } } ] root@752531364e2c:/# bpftool map dump pinned /opt/loxilb/dp/bpf/nat_v4_map [{ \"key\": { \"daddr\": 17435146, \"dport\": 58375, \"zone\": 0, \"l4proto\": 6 }, \"value\": { \"ca\": { \"act_type\": 5, \"ftrap\": 0, \"oif\": 0, \"cidx\": 1 }, \"lock\": { \"val\": 0 }, \"nxfrm\": 3, \"sel_hint\": 0, \"sel_type\": 0, \"nxfrms\": [{ \"nat_flags\": 0, \"inactive\": 0, \"wprio\": 1, \"res\": 0, \"nat_xport\": 35091, \"nat_xip\": 18816799 },{ \"nat_flags\": 0, \"inactive\": 0, \"wprio\": 2, \"res\": 0, \"nat_xport\": 35091, \"nat_xip\": 18882592 },{ \"nat_flags\": 0, \"inactive\": 0, \"wprio\": 2, \"res\": 0, \"nat_xport\": 35091, \"nat_xip\": 23356516 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 },{ \"nat_flags\": 0, \"inactive\": 1, \"wprio\": 0, \"res\": 0, \"nat_xport\": 0, \"nat_xip\": 0 } ] } } ] Check eBPF kernel debug logs Last but not the least, linux kernel outputs generic eBPF debug logs to /sys/kernel/debug/tracing/trace_pipe. Although loxilb eBPF modules do not emit logs in normal mode of operation, logs can be enabled after a recompilation. root@752531364e2c:/# cat /sys/kernel/debug/tracing/trace_pipe loxicmd-30524 [001] d.s1 27870.170790: bpf_trace_printk: out-dir loxicmd-30524 [001] d.s1 27870.170791: bpf_trace_printk: smr 4 loxicmd-30529 [000] d.s1 27871.617467: bpf_trace_printk: [CTRK] start loxicmd-30529 [000] d.s1 27871.617484: bpf_trace_printk: new-ct4 loxicmd-30529 [000] d.s1 27871.617486: bpf_trace_printk: in-dir loxicmd-30529 [000] d.s1 27871.617488: bpf_trace_printk: smr 0 loxicmd-30529 [000] d.s1 27871.617503: bpf_trace_printk: [CTRK] start loxicmd-30529 [000] d.s1 27871.617503: bpf_trace_printk: out-dir loxicmd-30529 [000] d.s1 27871.617504: bpf_trace_printk: smr 4 sshd-30790 [000] d.s1 27970.031847: bpf_trace_printk: [CTRK] start sshd-30790 [000] d.s1 27970.031866: bpf_trace_printk: new-ct4 sshd-30790 [000] d.s1 27970.031868: bpf_trace_printk: in-dir sshd-30790 [000] d.s1 27970.031870: bpf_trace_printk: smr 0 sshd-30790 [000] d.s1 27970.031887: bpf_trace_printk: [CTRK] start sshd-30790 [000] d.s1 27970.031887: bpf_trace_printk: out-dir sshd-30790 [000] d.s1 27970.031888: bpf_trace_printk: smr 0 sshd-30790 [000] d.s1 27970.031900: bpf_trace_printk: [CTRK] start","title":"loxilb - How to debug"},{"location":"ebpf/","text":"What is eBPF ?? eBPF has been making quite some news lately. An elegant way to extend the linux kernel (or windows) has far reaching implications. Although initially, eBPF was used to enhance system observability beyond existing tools, we will explore in this post how eBPF can be used for enhancing Linux networking performance. A quick recap The hooks that are of particular interest for this discussion are NIC hook (invoked just after packet is received at NIC) and TC hook (invoked just before Linux starts processing packet with its TCP/IP stack). Programs loaded to the former hook are also known as XDP programs and to the latter are called eBPF TC. Although both use eBPF restricted C syntax, there are significant differences between these types. (We will cover it in a separate blog later). For now, we just need to remember that when dealing with container-to-container or container-to-outside communication eBPF-TC makes much more sense since memory allocation (for skb) will happen either way in such scenarios. The performance bottlenecks Coming back to the focus of our discussion which is of course performance, let us step back and take a look at why Linux sucks at networking performance (or rather why it could perform much faster). Linux networking evolved from the days of dial up modem networking when speed was not of utmost importance. Down the lane, code kept accumulating. Although it is extremely feature rich and RFC compliant, it hardly resembles a powerful data-path networking engine. The following figure shows a call-trace of Linux kernel networking stack: The point is it has become incredibly complex over the years. Once features like NAT, VXLAN, conntrack etc come into play, Linux networking stops scaling due to cache degradation, lock contention etc. One problem leads to the another To avoid performance penalties, many user-space frameworks like DPDK have been widely used, which completely skip the linux kernel networking and directly process packets in the user-space. As simple as that may sound, there are some serious drawbacks in using such frameworks e.g need to dedicate cores (can\u2019t multitask), applications written on a specific user-space driver (PMD) might not run on another as it is, apps are also rendered incompatible across different DPDK releases frequently. Finally, there is a need to redo various parts of the TCP/IP stack and the provisioning involved. In short, it leads to a massive and completely unnecessary need of reinventing the wheel. We will have a detailed post later to discuss these factors. But for now, in short, if we are looking to get more out of a box than doing only networking, DPDK is not the right choice. In the age of distributed edge computing and immersive metaverse, the need to do more out of less is of utmost importance. eBPF comes to the rescue Now, eBPF changes all of this. eBPF is hosted inside the kernel so the biggest advantage of eBPF is it can co-exist with Linux/OS without the need of using dedicated cores, skipping the Kernel stack or breaking tools used for ages by the community. Handling of new protocols and functionality can be done in the fly without waiting for kernel development to catch up.","title":"What is eBPF"},{"location":"ebpf/#what-is-ebpf","text":"eBPF has been making quite some news lately. An elegant way to extend the linux kernel (or windows) has far reaching implications. Although initially, eBPF was used to enhance system observability beyond existing tools, we will explore in this post how eBPF can be used for enhancing Linux networking performance.","title":"What is eBPF ??"},{"location":"ebpf/#a-quick-recap","text":"The hooks that are of particular interest for this discussion are NIC hook (invoked just after packet is received at NIC) and TC hook (invoked just before Linux starts processing packet with its TCP/IP stack). Programs loaded to the former hook are also known as XDP programs and to the latter are called eBPF TC. Although both use eBPF restricted C syntax, there are significant differences between these types. (We will cover it in a separate blog later). For now, we just need to remember that when dealing with container-to-container or container-to-outside communication eBPF-TC makes much more sense since memory allocation (for skb) will happen either way in such scenarios.","title":"A quick recap"},{"location":"ebpf/#the-performance-bottlenecks","text":"Coming back to the focus of our discussion which is of course performance, let us step back and take a look at why Linux sucks at networking performance (or rather why it could perform much faster). Linux networking evolved from the days of dial up modem networking when speed was not of utmost importance. Down the lane, code kept accumulating. Although it is extremely feature rich and RFC compliant, it hardly resembles a powerful data-path networking engine. The following figure shows a call-trace of Linux kernel networking stack: The point is it has become incredibly complex over the years. Once features like NAT, VXLAN, conntrack etc come into play, Linux networking stops scaling due to cache degradation, lock contention etc.","title":"The performance bottlenecks"},{"location":"ebpf/#one-problem-leads-to-the-another","text":"To avoid performance penalties, many user-space frameworks like DPDK have been widely used, which completely skip the linux kernel networking and directly process packets in the user-space. As simple as that may sound, there are some serious drawbacks in using such frameworks e.g need to dedicate cores (can\u2019t multitask), applications written on a specific user-space driver (PMD) might not run on another as it is, apps are also rendered incompatible across different DPDK releases frequently. Finally, there is a need to redo various parts of the TCP/IP stack and the provisioning involved. In short, it leads to a massive and completely unnecessary need of reinventing the wheel. We will have a detailed post later to discuss these factors. But for now, in short, if we are looking to get more out of a box than doing only networking, DPDK is not the right choice. In the age of distributed edge computing and immersive metaverse, the need to do more out of less is of utmost importance.","title":"One problem leads to the another"},{"location":"ebpf/#ebpf-comes-to-the-rescue","text":"Now, eBPF changes all of this. eBPF is hosted inside the kernel so the biggest advantage of eBPF is it can co-exist with Linux/OS without the need of using dedicated cores, skipping the Kernel stack or breaking tools used for ages by the community. Handling of new protocols and functionality can be done in the fly without waiting for kernel development to catch up.","title":"eBPF comes to the rescue"},{"location":"faq/","text":"loxilb FAQs Does loxilb depend on what kind of CNI is deployed in the cluster ? Yes, loxilb configuration and operation might be related to which CNI (Calico, Cilium etc) is in use. loxilb just needs a way to find a route to its end-points. This also depends on how the network topology is laid out. For example, if a separated network for nodePort and external LB services is in effect or not. We will have a detailed guide on best practices for loxilb deployment soon. In the meantime, kindly reach out to us via github or loxilb forum Can loxilb be possibly run outside the released docker image ? Yes, loxilb can be run outside the provided docker image. Docker image gives it good portability across various linux like OS's without any performance impact. However, if need is to run outside its own docker, kindly follow README of various loxilb-io repositories. Can loxilb also act as a CNI ? loxilb supports all functionalities of a CNI but loxilb dev team is happy solving external LB and connectivity problems for the time being. If there is a future requirement, we might work on this as well Is there a commercially supported version of loxilb ? At this point of time, loxilb-team is working hard to provide a high-quality open-source product. If users need commercial support, kindly get in touch with us Can loxilb run in a standalone mode (without Kubernetes) ? Very much so. loxilb can run in a standalone mode. Please follow various guides available in loxilb repo to run loxilb in a standalone mode. How loxilb ensures conformance wtih Kubernetes ? loxilb uses kubetest/kubetest2 plus various other test-utilities as part of its CI/CD workflows. We are also planning to get ourselves officially supported by distros like RedHat Openshift Where is loxilb deployed so far ? loxilb is currently used in academia for R&D and various organizations are in process of using it for PoCs. We will update the list of deployments as and when they are officially known","title":"FAQs"},{"location":"faq/#loxilb-faqs","text":"Does loxilb depend on what kind of CNI is deployed in the cluster ? Yes, loxilb configuration and operation might be related to which CNI (Calico, Cilium etc) is in use. loxilb just needs a way to find a route to its end-points. This also depends on how the network topology is laid out. For example, if a separated network for nodePort and external LB services is in effect or not. We will have a detailed guide on best practices for loxilb deployment soon. In the meantime, kindly reach out to us via github or loxilb forum Can loxilb be possibly run outside the released docker image ? Yes, loxilb can be run outside the provided docker image. Docker image gives it good portability across various linux like OS's without any performance impact. However, if need is to run outside its own docker, kindly follow README of various loxilb-io repositories. Can loxilb also act as a CNI ? loxilb supports all functionalities of a CNI but loxilb dev team is happy solving external LB and connectivity problems for the time being. If there is a future requirement, we might work on this as well Is there a commercially supported version of loxilb ? At this point of time, loxilb-team is working hard to provide a high-quality open-source product. If users need commercial support, kindly get in touch with us Can loxilb run in a standalone mode (without Kubernetes) ? Very much so. loxilb can run in a standalone mode. Please follow various guides available in loxilb repo to run loxilb in a standalone mode. How loxilb ensures conformance wtih Kubernetes ? loxilb uses kubetest/kubetest2 plus various other test-utilities as part of its CI/CD workflows. We are also planning to get ourselves officially supported by distros like RedHat Openshift Where is loxilb deployed so far ? loxilb is currently used in academia for R&D and various organizations are in process of using it for PoCs. We will update the list of deployments as and when they are officially known","title":"loxilb FAQs"},{"location":"lb/","text":"What is service type external load-balancer in Kubernetes ? There are many different types of services like NodePort, ClusterIP etc. However, service type external load-balancer provides a way of exposing your application internally and/or externally in the perspective of the k8s cluster. Usually, Kubernetes CCM provider ensures that a load balancer of some sort is created, deleted and updated in your cloud. For on-prem or edge deployments however, organziations need to provide their own CCM load-balancer functions. MetalLB has been the choice for such cases for long. But edge services need to support so many exotic protocols in play like GTP, SCTP, SRv6 etc and integrating everything into a seamlessly working solution has been quite difficult. This is an area where loxilb aims to play a pivotal role. The following is a simple yaml config file which needs to be applied to create a service type load-balancer : \"type\": \"LoadBalancer\" { \"kind\": \"Service\", \"apiVersion\": \"v1\", \"metadata\": { \"name\": \"sample-service\" }, \"spec\": { \"ports\": [{ \"port\": 9001, \"targetPort\": 5001 }], \"selector\": { \"app\": \"sample\" }, \"type\": \"LoadBalancer\" } } However, if there is no K8s CCM plugin implementing external service load-balancer, such services won't be created and remain in pending state forever.","title":"What is service type external load-balancer"},{"location":"lb/#what-is-service-type-external-load-balancer-in-kubernetes","text":"There are many different types of services like NodePort, ClusterIP etc. However, service type external load-balancer provides a way of exposing your application internally and/or externally in the perspective of the k8s cluster. Usually, Kubernetes CCM provider ensures that a load balancer of some sort is created, deleted and updated in your cloud. For on-prem or edge deployments however, organziations need to provide their own CCM load-balancer functions. MetalLB has been the choice for such cases for long. But edge services need to support so many exotic protocols in play like GTP, SCTP, SRv6 etc and integrating everything into a seamlessly working solution has been quite difficult. This is an area where loxilb aims to play a pivotal role. The following is a simple yaml config file which needs to be applied to create a service type load-balancer : \"type\": \"LoadBalancer\" { \"kind\": \"Service\", \"apiVersion\": \"v1\", \"metadata\": { \"name\": \"sample-service\" }, \"spec\": { \"ports\": [{ \"port\": 9001, \"targetPort\": 5001 }], \"selector\": { \"app\": \"sample\" }, \"type\": \"LoadBalancer\" } } However, if there is no K8s CCM plugin implementing external service load-balancer, such services won't be created and remain in pending state forever.","title":"What is service type external load-balancer in Kubernetes ?"},{"location":"loxilbebpf/","text":"loxilb eBPF implementation details In this section, we will look into details of loxilb ebpf implementation in little details and try to check what goes on under the hood. When loxilb is build, it builds two object files as follows : llb@nd2:~/loxilb$ ls -l /opt/loxilb/ total 396 drwxrwxrwt 3 root root 0 6?? 20 11:17 dp -rw-rw-r-- 1 llb llb 305536 6?? 29 09:39 llb_ebpf_main.o -rw-rw-r-- 1 llb llb 95192 6?? 29 09:39 llb_xdp_main.o As the name suggests and based on hook point, xdp version does XDP packet processing while ebpf version is used at TC layer for TC eBPF processing. Interesting enough, the packet forwarding code is largely agnostic of its final hook point due to usage of a light abstraction layer to hide differences between eBPF and XDP layer. Now this beckons the question why separate hook points and how does it all work together ? loxilb does bulk of its processing at TC eBPF layer as this layer is most optimized for doing L4+ processing needed for loxilb operation. XDP's frame format is different than what is used by skb (linux kernel's generic socket buffer). This makes it very difficult (if not impossible) to do tcp checksum offload and other such features used by linux networking stack for quite some time now. In short, if we need to do such operations, XDP performance will be inherently slow. XDP as such is perfect for quick operations at l2 layer. loxilb uses XDP to do certain operations like mirroring. Due to how TC eBPF works, it is difficult to work with multiple packet copies and loxilb's TC eBPF offloads some functinality to XDP layer in such special cases. Loading of loxilb eBPF program loxilb's goLang based agent by default loads the loxilb ebpf programs in all the interfaces(only physical/real/bond/wireguard) available in the system. As loxilb is designed to run in its own docker/container, this is convenient for users who dont want to have to manually load/unload eBPF programs. However, it is still possible to do so manually if need arises : To load : ntc filter add dev eth1 ingress bpf da obj /opt/loxilb/llb_ebpf_main.o sec tc_packet_parser To unload: ntc filter del dev eth1 ingress To check: root@nd2:/home/llb# ntc filter show dev hs2 ingress filter protocol all pref 49152 bpf chain 0 filter protocol all pref 49152 bpf chain 0 handle 0x1 llb_ebpf_main.o:[tc_packet_parser] direct-action not_in_hw id 8715 tag 43a829222e969bce jited Please not that ntc is the customized tc tool from iproute2 package which can be found in loxilb's repository Entry points of loxilb eBPF loxilb's eBPF code is usually divided into two program sections with the following entry functions : tc_packet_func\\ This alongwith the consequent code does majority of the packet processing. If conntrack entries are in established state, this is also responsible for packet tx. However if conntrack entry for a particular packet flow is not established, it makes a bpf tail call to the tc_packet_func_slow tc_packet_func_slow\\ This is responsible mainly for doing NAT lookup and stateful conntrack implementation. Once conntrack entry transitions to established state, the forwarding then can happen directly from tc_packet_func loxilb's XDP code is contained in the following section : xdp_packet_func\\ This is the entry point for packet processing when hook point is XDP instead of TC eBPF Pinned Maps of loxilb eBPF All maps used by loxilb eBPF are mounted in the file-system as below : root@nd2:/home/llb/loxilb# ls -lart /opt/loxilb/dp/ total 4 drwxrwxrwt 3 root root 0 6?? 20 11:17 . drwxr-xr-x 3 root root 4096 6?? 29 10:19 .. drwx------ 3 root root 0 6?? 29 10:19 bpf root@nd2:/home/llb/loxilb# mount | grep bpf none on /opt/netlox/loxilb type bpf (rw,relatime) root@nd2:/home/llb/loxilb# ls -lart /opt/loxilb/dp/bpf/ total 0 drwxrwxrwt 3 root root 0 6?? 20 11:17 .. lrwxrwxrwx 1 root root 0 6?? 20 11:17 xdp -> /opt/loxilb/dp/bpf//tc/ drwx------ 3 root root 0 6?? 20 11:17 tc lrwxrwxrwx 1 root root 0 6?? 20 11:17 ip -> /opt/loxilb/dp/bpf//tc/ -rw------- 1 root root 0 6?? 29 10:19 xfis -rw------- 1 root root 0 6?? 29 10:19 xfck -rw------- 1 root root 0 6?? 29 10:19 xctk -rw------- 1 root root 0 6?? 29 10:19 tx_intf_stats_map -rw------- 1 root root 0 6?? 29 10:19 tx_intf_map -rw------- 1 root root 0 6?? 29 10:19 tx_bd_stats_map -rw------- 1 root root 0 6?? 29 10:19 tmac_stats_map -rw------- 1 root root 0 6?? 29 10:19 tmac_map -rw------- 1 root root 0 6?? 29 10:19 smac_map -rw------- 1 root root 0 6?? 29 10:19 rt_v6_stats_map -rw------- 1 root root 0 6?? 29 10:19 rt_v4_stats_map -rw------- 1 root root 0 6?? 29 10:19 rt_v4_map -rw------- 1 root root 0 6?? 29 10:19 polx_map -rw------- 1 root root 0 6?? 29 10:19 pkts -rw------- 1 root root 0 6?? 29 10:19 pkt_ring -rw------- 1 root root 0 6?? 29 10:19 pgm_tbl -rw------- 1 root root 0 6?? 29 10:19 nh_map -rw------- 1 root root 0 6?? 29 10:19 nat_v4_map -rw------- 1 root root 0 6?? 29 10:19 mirr_map -rw------- 1 root root 0 6?? 29 10:19 intf_stats_map -rw------- 1 root root 0 6?? 29 10:19 intf_map -rw------- 1 root root 0 6?? 29 10:19 fc_v4_stats_map -rw------- 1 root root 0 6?? 29 10:19 fc_v4_map -rw------- 1 root root 0 6?? 29 10:19 fcas -rw------- 1 root root 0 6?? 29 10:19 dmac_map -rw------- 1 root root 0 6?? 29 10:19 ct_v4_map -rw------- 1 root root 0 6?? 29 10:19 bd_stats_map -rw------- 1 root root 0 6?? 29 10:19 acl_v6_stats_map -rw------- 1 root root 0 6?? 29 10:19 acl_v4_stats_map -rw------- 1 root root 0 6?? 29 10:19 acl_v4_map Using bpftool, it is easy to check state of these maps as follows : root@nd2:/home/llb# bpftool map dump pinned /opt/loxilb/dp/bpf/intf_map [{ \"key\": { \"ifindex\": 2, \"ing_vid\": 0, \"pad\": 0 }, \"value\": { \"ca\": { \"act_type\": 11, \"ftrap\": 0, \"oif\": 0, \"cidx\": 0 }, \"\": { \"set_ifi\": { \"xdp_ifidx\": 1, \"zone\": 0, \"bd\": 3801, \"mirr\": 0, \"polid\": 0, \"r\": [0,0,0,0,0,0 ] } } } },{ \"key\": { \"ifindex\": 3, \"ing_vid\": 0, \"pad\": 0 }, \"value\": { \"ca\": { \"act_type\": 11, \"ftrap\": 0, \"oif\": 0, \"cidx\": 0 }, \"\": { \"set_ifi\": { \"xdp_ifidx\": 3, \"zone\": 0, \"bd\": 3803, \"mirr\": 0, \"polid\": 0, \"r\": [0,0,0,0,0,0 ] } } } } ] As our development progresses, we will keep updating details about these map's internals loxilb eBPF pipeline at a glance The following figure shows a very high-level diagram of packet flow through loxilb eBPF pipeline : We use eBPF tail calls to jump from one section to another majorly due to the fact that there is clear separation for CT (conntrack) functionality and packet-forwarding logic. At the same time, kernel's built in eBPF-verifier imposes a maximum code size limit for a single program.","title":"loxilb eBPF implementation details"},{"location":"loxilbebpf/#loxilb-ebpf-implementation-details","text":"In this section, we will look into details of loxilb ebpf implementation in little details and try to check what goes on under the hood. When loxilb is build, it builds two object files as follows : llb@nd2:~/loxilb$ ls -l /opt/loxilb/ total 396 drwxrwxrwt 3 root root 0 6?? 20 11:17 dp -rw-rw-r-- 1 llb llb 305536 6?? 29 09:39 llb_ebpf_main.o -rw-rw-r-- 1 llb llb 95192 6?? 29 09:39 llb_xdp_main.o As the name suggests and based on hook point, xdp version does XDP packet processing while ebpf version is used at TC layer for TC eBPF processing. Interesting enough, the packet forwarding code is largely agnostic of its final hook point due to usage of a light abstraction layer to hide differences between eBPF and XDP layer. Now this beckons the question why separate hook points and how does it all work together ? loxilb does bulk of its processing at TC eBPF layer as this layer is most optimized for doing L4+ processing needed for loxilb operation. XDP's frame format is different than what is used by skb (linux kernel's generic socket buffer). This makes it very difficult (if not impossible) to do tcp checksum offload and other such features used by linux networking stack for quite some time now. In short, if we need to do such operations, XDP performance will be inherently slow. XDP as such is perfect for quick operations at l2 layer. loxilb uses XDP to do certain operations like mirroring. Due to how TC eBPF works, it is difficult to work with multiple packet copies and loxilb's TC eBPF offloads some functinality to XDP layer in such special cases.","title":"loxilb eBPF implementation details"},{"location":"loxilbebpf/#loading-of-loxilb-ebpf-program","text":"loxilb's goLang based agent by default loads the loxilb ebpf programs in all the interfaces(only physical/real/bond/wireguard) available in the system. As loxilb is designed to run in its own docker/container, this is convenient for users who dont want to have to manually load/unload eBPF programs. However, it is still possible to do so manually if need arises : To load : ntc filter add dev eth1 ingress bpf da obj /opt/loxilb/llb_ebpf_main.o sec tc_packet_parser To unload: ntc filter del dev eth1 ingress To check: root@nd2:/home/llb# ntc filter show dev hs2 ingress filter protocol all pref 49152 bpf chain 0 filter protocol all pref 49152 bpf chain 0 handle 0x1 llb_ebpf_main.o:[tc_packet_parser] direct-action not_in_hw id 8715 tag 43a829222e969bce jited Please not that ntc is the customized tc tool from iproute2 package which can be found in loxilb's repository","title":"Loading of loxilb eBPF program"},{"location":"loxilbebpf/#entry-points-of-loxilb-ebpf","text":"loxilb's eBPF code is usually divided into two program sections with the following entry functions : tc_packet_func\\ This alongwith the consequent code does majority of the packet processing. If conntrack entries are in established state, this is also responsible for packet tx. However if conntrack entry for a particular packet flow is not established, it makes a bpf tail call to the tc_packet_func_slow tc_packet_func_slow\\ This is responsible mainly for doing NAT lookup and stateful conntrack implementation. Once conntrack entry transitions to established state, the forwarding then can happen directly from tc_packet_func loxilb's XDP code is contained in the following section : xdp_packet_func\\ This is the entry point for packet processing when hook point is XDP instead of TC eBPF","title":"Entry points of loxilb eBPF"},{"location":"loxilbebpf/#pinned-maps-of-loxilb-ebpf","text":"All maps used by loxilb eBPF are mounted in the file-system as below : root@nd2:/home/llb/loxilb# ls -lart /opt/loxilb/dp/ total 4 drwxrwxrwt 3 root root 0 6?? 20 11:17 . drwxr-xr-x 3 root root 4096 6?? 29 10:19 .. drwx------ 3 root root 0 6?? 29 10:19 bpf root@nd2:/home/llb/loxilb# mount | grep bpf none on /opt/netlox/loxilb type bpf (rw,relatime) root@nd2:/home/llb/loxilb# ls -lart /opt/loxilb/dp/bpf/ total 0 drwxrwxrwt 3 root root 0 6?? 20 11:17 .. lrwxrwxrwx 1 root root 0 6?? 20 11:17 xdp -> /opt/loxilb/dp/bpf//tc/ drwx------ 3 root root 0 6?? 20 11:17 tc lrwxrwxrwx 1 root root 0 6?? 20 11:17 ip -> /opt/loxilb/dp/bpf//tc/ -rw------- 1 root root 0 6?? 29 10:19 xfis -rw------- 1 root root 0 6?? 29 10:19 xfck -rw------- 1 root root 0 6?? 29 10:19 xctk -rw------- 1 root root 0 6?? 29 10:19 tx_intf_stats_map -rw------- 1 root root 0 6?? 29 10:19 tx_intf_map -rw------- 1 root root 0 6?? 29 10:19 tx_bd_stats_map -rw------- 1 root root 0 6?? 29 10:19 tmac_stats_map -rw------- 1 root root 0 6?? 29 10:19 tmac_map -rw------- 1 root root 0 6?? 29 10:19 smac_map -rw------- 1 root root 0 6?? 29 10:19 rt_v6_stats_map -rw------- 1 root root 0 6?? 29 10:19 rt_v4_stats_map -rw------- 1 root root 0 6?? 29 10:19 rt_v4_map -rw------- 1 root root 0 6?? 29 10:19 polx_map -rw------- 1 root root 0 6?? 29 10:19 pkts -rw------- 1 root root 0 6?? 29 10:19 pkt_ring -rw------- 1 root root 0 6?? 29 10:19 pgm_tbl -rw------- 1 root root 0 6?? 29 10:19 nh_map -rw------- 1 root root 0 6?? 29 10:19 nat_v4_map -rw------- 1 root root 0 6?? 29 10:19 mirr_map -rw------- 1 root root 0 6?? 29 10:19 intf_stats_map -rw------- 1 root root 0 6?? 29 10:19 intf_map -rw------- 1 root root 0 6?? 29 10:19 fc_v4_stats_map -rw------- 1 root root 0 6?? 29 10:19 fc_v4_map -rw------- 1 root root 0 6?? 29 10:19 fcas -rw------- 1 root root 0 6?? 29 10:19 dmac_map -rw------- 1 root root 0 6?? 29 10:19 ct_v4_map -rw------- 1 root root 0 6?? 29 10:19 bd_stats_map -rw------- 1 root root 0 6?? 29 10:19 acl_v6_stats_map -rw------- 1 root root 0 6?? 29 10:19 acl_v4_stats_map -rw------- 1 root root 0 6?? 29 10:19 acl_v4_map Using bpftool, it is easy to check state of these maps as follows : root@nd2:/home/llb# bpftool map dump pinned /opt/loxilb/dp/bpf/intf_map [{ \"key\": { \"ifindex\": 2, \"ing_vid\": 0, \"pad\": 0 }, \"value\": { \"ca\": { \"act_type\": 11, \"ftrap\": 0, \"oif\": 0, \"cidx\": 0 }, \"\": { \"set_ifi\": { \"xdp_ifidx\": 1, \"zone\": 0, \"bd\": 3801, \"mirr\": 0, \"polid\": 0, \"r\": [0,0,0,0,0,0 ] } } } },{ \"key\": { \"ifindex\": 3, \"ing_vid\": 0, \"pad\": 0 }, \"value\": { \"ca\": { \"act_type\": 11, \"ftrap\": 0, \"oif\": 0, \"cidx\": 0 }, \"\": { \"set_ifi\": { \"xdp_ifidx\": 3, \"zone\": 0, \"bd\": 3803, \"mirr\": 0, \"polid\": 0, \"r\": [0,0,0,0,0,0 ] } } } } ] As our development progresses, we will keep updating details about these map's internals","title":"Pinned Maps of loxilb eBPF"},{"location":"loxilbebpf/#loxilb-ebpf-pipeline-at-a-glance","text":"The following figure shows a very high-level diagram of packet flow through loxilb eBPF pipeline : We use eBPF tail calls to jump from one section to another majorly due to the fact that there is clear separation for CT (conntrack) functionality and packet-forwarding logic. At the same time, kernel's built in eBPF-verifier imposes a maximum code size limit for a single program.","title":"loxilb eBPF pipeline at a glance"},{"location":"perf/","text":"loxilb Performance To be updated","title":"Performance"},{"location":"perf/#loxilb-performance","text":"To be updated","title":"loxilb Performance"},{"location":"roadmap/","text":"Release Notes 0.0.1 beta (Jul, 2021) Initial release of loxilb Major functions : Two-Arm Load-Balancer (NAT+Routed mode) 16 end-points (arms) support Load-balancer selection policy Round-robin, traffic-hash (fallback to RR if hash fails) Conntrack support in eBPF - TCP/UDP/ICMP profiles GTP with QFI extension support UL/CL classifier support for MEC Extended QoS support (SRTCM/TRTCM) Support for GoBGP Support for Calico CNI Extended visibility and statistics CCM Support : IP allocation policy Kubernetes 1.20 base support Utilities : loxicmd support : Configuration utlity with the look and feel of kubectl loxidump support : Config export and import utility 0.0.2 (Oct, 2022) - Planned Major functions : Enhanced load-balancer support upto 32 end-points Integrated Firewall support Extended conntrack - SCTP support One-ARM LB mode support SRv6 support HA support Grafana based dashboard CCM Support : OpenShift Integration DPU Support : Nvidia BF2 Support","title":"Development Roadmap"},{"location":"roadmap/#release-notes","text":"","title":"Release Notes"},{"location":"roadmap/#001-beta-jul-2021","text":"Initial release of loxilb Major functions : Two-Arm Load-Balancer (NAT+Routed mode) 16 end-points (arms) support Load-balancer selection policy Round-robin, traffic-hash (fallback to RR if hash fails) Conntrack support in eBPF - TCP/UDP/ICMP profiles GTP with QFI extension support UL/CL classifier support for MEC Extended QoS support (SRTCM/TRTCM) Support for GoBGP Support for Calico CNI Extended visibility and statistics CCM Support : IP allocation policy Kubernetes 1.20 base support Utilities : loxicmd support : Configuration utlity with the look and feel of kubectl loxidump support : Config export and import utility","title":"0.0.1 beta (Jul, 2021)"},{"location":"roadmap/#002-oct-2022-planned","text":"Major functions : Enhanced load-balancer support upto 32 end-points Integrated Firewall support Extended conntrack - SCTP support One-ARM LB mode support SRv6 support HA support Grafana based dashboard CCM Support : OpenShift Integration DPU Support : Nvidia BF2 Support","title":"0.0.2 (Oct, 2022) - Planned"},{"location":"run/","text":"loxilb - How to build/run Right from code (difficult) Build custom iproute2 package git clone https://github.com/loxilb-io/iproute2.git cd iproute2 cd libbpf/src/ mkdir build DESTDIR=build make install cd ../../ export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:`pwd`/libbpf/src/ LIBBPF_FORCE=on LIBBPF_DIR=`pwd`/libbpf/src/build ./configure make sudo cp -f tc/tc /usr/local/sbin/ntc Build and run loxilb git clone https://github.com/loxilb-io/loxilb.git cd loxilb ./ebpf/utils/mkllb_bpffs.sh make cd ebpf/libbpf/src sudo make install cd - sudo ./loxilb To run with integrated api-server, we can use the following : ./loxilb --tls-key=api/certification/server.key --tls-certificate=api/certification/server.crt --host=0.0.0.0 --port=11111 --tls-port=8091 -a From docker (easy) Get the loxilb official docker image docker pull loxilbio/loxilb:beta To run loxilb docker, we can use the following commands : docker run -u root --cap-add SYS_ADMIN --restart unless-stopped --privileged -dit -v /dev/log:/dev/log -v /var/run/:/var/run --name loxilb loxilbio/loxilb:beta To drop in to a shell of loxilb doker : docker exec -it loxilb bash For load-balancing to effetively work in a bare-metal environment, we need multiple interfaces assigned to the docker (external and internal connectivitiy) loxilb docker relies on docker's macvlan driver for achieving this. The following is an example of creating macvlan network and using with loxilb # Create a mac-vlan (on an underlying interface enp0s3) docker network create -d macvlan -o parent=enp0s3 --subnet 172.30.1.0/24 --gateway 172.30.1.254 --aux-address 'host=172.30.1.193\u2019 llbnet # Run loxilb docker with the created macvlan docker run -u root --cap-add SYS_ADMIN --restart unless-stopped --privileged -dit -v /dev/log:/dev/log -v /var/run/:/var/run --net=llbnet --ip=172.30.1.193 --name loxilb loxilbio/loxilb:beta # If we still want to connect loxilb docker additionally to docker's default network or more macvlan networks docker network connect bridge loxilb Note - While working with macvlan interfaces, the parent/underlying interface should be put in promiscous mode Finally, to run loxilb docker with all modules loaded, the following command can be used : docker run -u root --cap-add SYS_ADMIN --restart unless-stopped --privileged -dit -v /dev/log:/dev/log -v /var/run/:/var/run --net=llbnet --ip=172.30.1.193 --entrypoint /root/loxilb-io/loxilb/loxilb --name loxilb loxilbio/loxilb:beta --tls-key=/root/loxilb-io/loxilb/api/certification/server.key --tls-certificate=/root/loxilb-io/loxilb/api/certification/server.crt --host=0.0.0.0 --port=11111 --tls-port=8091 -a","title":"How to build/run"},{"location":"run/#loxilb-how-to-buildrun","text":"","title":"loxilb - How to build/run"},{"location":"run/#right-from-code-difficult","text":"Build custom iproute2 package git clone https://github.com/loxilb-io/iproute2.git cd iproute2 cd libbpf/src/ mkdir build DESTDIR=build make install cd ../../ export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:`pwd`/libbpf/src/ LIBBPF_FORCE=on LIBBPF_DIR=`pwd`/libbpf/src/build ./configure make sudo cp -f tc/tc /usr/local/sbin/ntc Build and run loxilb git clone https://github.com/loxilb-io/loxilb.git cd loxilb ./ebpf/utils/mkllb_bpffs.sh make cd ebpf/libbpf/src sudo make install cd - sudo ./loxilb To run with integrated api-server, we can use the following : ./loxilb --tls-key=api/certification/server.key --tls-certificate=api/certification/server.crt --host=0.0.0.0 --port=11111 --tls-port=8091 -a","title":"Right from code (difficult)"},{"location":"run/#from-docker-easy","text":"Get the loxilb official docker image docker pull loxilbio/loxilb:beta To run loxilb docker, we can use the following commands : docker run -u root --cap-add SYS_ADMIN --restart unless-stopped --privileged -dit -v /dev/log:/dev/log -v /var/run/:/var/run --name loxilb loxilbio/loxilb:beta To drop in to a shell of loxilb doker : docker exec -it loxilb bash For load-balancing to effetively work in a bare-metal environment, we need multiple interfaces assigned to the docker (external and internal connectivitiy) loxilb docker relies on docker's macvlan driver for achieving this. The following is an example of creating macvlan network and using with loxilb # Create a mac-vlan (on an underlying interface enp0s3) docker network create -d macvlan -o parent=enp0s3 --subnet 172.30.1.0/24 --gateway 172.30.1.254 --aux-address 'host=172.30.1.193\u2019 llbnet # Run loxilb docker with the created macvlan docker run -u root --cap-add SYS_ADMIN --restart unless-stopped --privileged -dit -v /dev/log:/dev/log -v /var/run/:/var/run --net=llbnet --ip=172.30.1.193 --name loxilb loxilbio/loxilb:beta # If we still want to connect loxilb docker additionally to docker's default network or more macvlan networks docker network connect bridge loxilb Note - While working with macvlan interfaces, the parent/underlying interface should be put in promiscous mode Finally, to run loxilb docker with all modules loaded, the following command can be used : docker run -u root --cap-add SYS_ADMIN --restart unless-stopped --privileged -dit -v /dev/log:/dev/log -v /var/run/:/var/run --net=llbnet --ip=172.30.1.193 --entrypoint /root/loxilb-io/loxilb/loxilb --name loxilb loxilbio/loxilb:beta --tls-key=/root/loxilb-io/loxilb/api/certification/server.key --tls-certificate=/root/loxilb-io/loxilb/api/certification/server.crt --host=0.0.0.0 --port=11111 --tls-port=8091 -a","title":"From docker (easy)"}]}